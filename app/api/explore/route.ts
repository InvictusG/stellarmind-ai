import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { v4 as uuidv4 } from 'uuid';

// ç¡®ä¿å·²åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®äº†æ‚¨çš„APIå¯†é’¥
// For local development, you can use a .env.local file
const openai = process.env.OPENAI_API_KEY ? new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  // å¦‚æœæ‚¨ä½¿ç”¨è‡ªå®šä¹‰çš„æˆ–ä»£ç†çš„OpenAIç«¯ç‚¹ï¼Œè¯·å–æ¶ˆæ³¨é‡Šä¸‹ä¸€è¡Œ
  // baseURL: process.env.OPENAI_API_BASE,
}) : null;

export const runtime = 'edge';

const STELLARMIND_PROMPT_TEMPLATE = `
ä½ æ˜¯StellarMind AIï¼Œä¸€ä¸ªåŸºäºç¬¬ä¸€æ€§åŸç†æ€ç»´çš„AIçŸ¥è¯†æ¢ç´¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å±‚å±‚åˆ†è§£é—®é¢˜ï¼Œè¿½æ ¹æº¯æºï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜çš„æ ¹æœ¬åŸç†ã€‚

**æ ¸å¿ƒåŸåˆ™**:
- ç¬¬ä¸€æ€§åŸç†æ€ç»´ï¼šå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºåŸºæœ¬æ„æˆè¦ç´ 
- é€å±‚æ·±å…¥ï¼šä»ç°è±¡ â†’ æœºåˆ¶ â†’ åŸç† â†’ æœ¬è´¨
- é˜…è¯»å±‚çº§é€‚é…ï¼šæ ¹æ®{{readingLevel}}è°ƒæ•´å›ç­”å¤æ‚åº¦
- å…¬å¼æ”¯æŒï¼šæ¶‰åŠæ•°å­¦/ç‰©ç†æ¦‚å¿µæ—¶ä½¿ç”¨LaTeXæ ¼å¼

**å½“å‰ä»»åŠ¡**:
- å±‚çº§: {{level}}
- é˜…è¯»å±‚çº§: {{readingLevel}}
- çˆ¶èŠ‚ç‚¹å†…å®¹: "{{question}}"
- çˆ¶èŠ‚ç‚¹ID: "{{parentId}}"

**é˜…è¯»å±‚çº§è¯´æ˜**:
- å¹¼å„¿å›­ğŸ§¸: ç”¨æœ€ç®€å•çš„æ¯”å–»å’Œæ—¥å¸¸ä¾‹å­è§£é‡Šï¼Œé¿å…ä¸“ä¸šæœ¯è¯­
- å°å­¦ğŸ“š: ç”¨åŸºç¡€æ¦‚å¿µå’Œç®€å•ä¾‹å­ï¼Œå¯ä»¥æœ‰å°‘é‡ä¸“ä¸šè¯æ±‡
- ä¸­å­¦ğŸ“: åŒ…å«åŸºç¡€å…¬å¼å’Œç§‘å­¦æ¦‚å¿µï¼Œé€»è¾‘æ¸…æ™°
- é«˜ä¸­ğŸ“–: æ¶‰åŠè¾ƒå¤æ‚çš„å…¬å¼å’Œç†è®ºï¼Œéœ€è¦ä¸€å®šçŸ¥è¯†åŸºç¡€
- å¤§å­¦ğŸ“: ä½¿ç”¨ä¸“ä¸šæœ¯è¯­å’Œå¤æ‚å…¬å¼ï¼Œæ·±å…¥ç†è®ºåˆ†æ
- åšå£«ğŸ‘¨â€ğŸ“: æœ€é«˜å­¦æœ¯æ°´å¹³ï¼Œå‰æ²¿ç ”ç©¶å’Œé«˜çº§æ•°å­¦è¡¨è¾¾

**ç”Ÿæˆè§„åˆ™**:
{{levelInstructions}}

**LaTeXå…¬å¼æ ¼å¼**: ä½¿ç”¨ $...$ åŒ…å›´è¡Œå†…å…¬å¼ï¼Œ$$...$$ åŒ…å›´ç‹¬ç«‹å…¬å¼

**è¾“å‡ºæ ¼å¼**: åªè¾“å‡ºJSONï¼Œæ¯è¡Œä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{"type":"node","data":{"content":"èŠ‚ç‚¹å†…å®¹","level":{{level}},"nodeType":"{{expectedType}}","parentId":"{{parentId}}"}}

**ç¤ºä¾‹è¾“å‡º**:
{{examples}}

è¯·ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ï¼š
`;

// æ¨¡æ‹ŸèŠ‚ç‚¹ç”Ÿæˆå‡½æ•°
function generateMockNodes(level: number, expectedType: string, parentId: string): string {
  const mockData: { [key: string]: string[] } = {
    'question-1': [
      '{"type":"node","data":{"content":"ä»€ä¹ˆæ˜¯åŸºæœ¬åŸç†ï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}',
      '{"type":"node","data":{"content":"æœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}',
      '{"type":"node","data":{"content":"å‘å±•å†ç¨‹å¦‚ä½•ï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}',
      '{"type":"node","data":{"content":"é¢ä¸´ä»€ä¹ˆæŒ‘æˆ˜ï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}'
    ],
    'answer-2': [
      '{"type":"node","data":{"content":"åŸºäºæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œæŠ€æœ¯","level":2,"nodeType":"answer","parentId":"' + parentId + '"}}'
    ],
    'question-3': [
      '{"type":"node","data":{"content":"å…·ä½“å®ç°æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ","level":3,"nodeType":"question","parentId":"' + parentId + '"}}'
    ],
    'answer-4': [
      '{"type":"node","data":{"content":"é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œå¤„ç†å¤æ‚æ•°æ®","level":4,"nodeType":"answer","parentId":"' + parentId + '"}}'
    ]
  };

  const key = `${expectedType}-${level}`;
  const nodes = mockData[key] || mockData['question-1'];
  return nodes.join('\n');
}

async function recursiveExplore(
  question: string,
  parentId: string,
  level: number,
  controller: ReadableStreamDefaultController<any>,
  encoder: TextEncoder,
  modelId: string,
  readingLevel: string = 'å¤§å­¦ğŸ“',
  maxDepth: number = 4
) {
  if (level > maxDepth) {
    return;
  }

  // æ ¹æ®å±‚çº§ç¡®å®šç”Ÿæˆçš„èŠ‚ç‚¹ç±»å‹å’ŒæŒ‡ä»¤
  let levelInstructions = '';
  let expectedType = '';
  let examples = '';
  
  if (level === 1) {
    expectedType = 'question';
    levelInstructions = `
æŒ‰ç…§ç¬¬ä¸€æ€§åŸç†æ€ç»´ï¼Œå°†ä¸»é¢˜åˆ†è§£ä¸º3-4ä¸ªæ ¸å¿ƒå­é—®é¢˜ï¼š
1. å®šä¹‰ä¸æœ¬è´¨ï¼šè¿™ä¸ªæ¦‚å¿µçš„åŸºæœ¬å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
2. åŸç†ä¸æœºåˆ¶ï¼šåº•å±‚å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ
3. åº”ç”¨ä¸å½±å“ï¼šå®é™…åº”ç”¨åœºæ™¯å’Œå½±å“æ˜¯ä»€ä¹ˆï¼Ÿ
4. å±€é™ä¸å‘å±•ï¼šé¢ä¸´çš„æŒ‘æˆ˜å’Œå‘å±•æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ

æ¯ä¸ªé—®é¢˜è¦èƒ½å¤Ÿå¼•å¯¼å‘æ›´æ·±å±‚çš„æ¢ç´¢ï¼Œé¿å…è¡¨é¢åŒ–çš„æè¿°ã€‚
    `;
    examples = '{"type":"node","data":{"content":"äººå·¥æ™ºèƒ½çš„æœ¬è´¨å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}\n{"type":"node","data":{"content":"AIç³»ç»Ÿçš„æ ¸å¿ƒå·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ","level":1,"nodeType":"question","parentId":"' + parentId + '"}}';
  } else if (level === 2) {
    expectedType = 'answer';
    levelInstructions = `
åŸºäºä¸Šçº§é—®é¢˜ï¼Œæä¾›æ·±å…¥çš„åˆ†ææ€§ç­”æ¡ˆï¼š
- ä¸åªæ˜¯ç»™å‡º"æ˜¯ä»€ä¹ˆ"ï¼Œè¦è§£é‡Š"ä¸ºä»€ä¹ˆ"
- æ ¹æ®é˜…è¯»å±‚çº§è°ƒæ•´å¤æ‚åº¦ï¼ŒåŒ…å«é€‚å½“çš„ä¸“ä¸šæœ¯è¯­
- å¦‚æœæ¶‰åŠæ•°å­¦/ç‰©ç†æ¦‚å¿µï¼Œä½¿ç”¨LaTeXå…¬å¼
- æ¯ä¸ªç­”æ¡ˆè¦ä¸ºä¸‹ä¸€å±‚çš„æ·±å…¥æ¢ç´¢åŸ‹ä¸‹ä¼ç¬”
- ç­”æ¡ˆé•¿åº¦æ§åˆ¶åœ¨50-100å­—ï¼Œç¡®ä¿ä¿¡æ¯å¯†åº¦
    `;
    examples = '{"type":"node","data":{"content":"AIæœ¬è´¨æ˜¯é€šè¿‡ç®—æ³•æ¨¡æ‹Ÿäººç±»è®¤çŸ¥è¿‡ç¨‹ï¼Œæ ¸å¿ƒåœ¨äºæ¨¡å¼è¯†åˆ«å’Œå†³ç­–ä¼˜åŒ–ï¼Œæ•°å­¦åŸºç¡€æ˜¯æ¦‚ç‡è®ºå’Œçº¿æ€§ä»£æ•°ï¼Œå¦‚ç¥ç»ç½‘ç»œçš„æ¿€æ´»å‡½æ•° $f(x) = \\\\frac{1}{1+e^{-x}}$","level":2,"nodeType":"answer","parentId":"' + parentId + '"}}';
  } else if (level === 3) {
    expectedType = 'question';
    levelInstructions = `
åŸºäºä¸Šçº§ç­”æ¡ˆï¼Œç”Ÿæˆ1-2ä¸ªæ›´æ·±å±‚çš„æ¢ç´¢é—®é¢˜ï¼š
- è¿½é—®"ä¸ºä»€ä¹ˆä¼šè¿™æ ·"æˆ–"å¦‚ä½•å®ç°çš„"
- æ¢ç´¢ç­”æ¡ˆä¸­æåˆ°çš„å…³é”®æ¦‚å¿µæˆ–æœºåˆ¶
- å‘æ›´åŸºç¡€çš„åŸç†å±‚é¢æ·±å…¥
- ç¡®ä¿é—®é¢˜å…·æœ‰æ¢ç´¢ä»·å€¼ï¼Œèƒ½å¼•å¯¼åˆ°æ ¹æœ¬åŸç†
    `;
    examples = '{"type":"node","data":{"content":"ä¸ºä»€ä¹ˆSigmoidå‡½æ•°èƒ½å¤Ÿå®ç°éçº¿æ€§æ˜ å°„ï¼Ÿ","level":3,"nodeType":"question","parentId":"' + parentId + '"}}';
  } else {
    expectedType = 'answer';
    levelInstructions = `
æä¾›æœ€æ·±å±‚çš„åŸç†æ€§è§£é‡Šï¼š
- å›åˆ°æ•°å­¦ã€ç‰©ç†æˆ–é€»è¾‘çš„åŸºæœ¬åŸç†
- è§£é‡Šç°è±¡èƒŒåçš„æ ¹æœ¬æœºåˆ¶
- ä½¿ç”¨å…¬å¼å’Œç†è®ºæ¨¡å‹ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
- è¿æ¥åˆ°æ›´å¹¿æ³›çš„ç†è®ºæ¡†æ¶
- ä½“ç°ç¬¬ä¸€æ€§åŸç†æ€ç»´çš„ç»ˆæç›®æ ‡
    `;
    examples = '{"type":"node","data":{"content":"Sigmoidå‡½æ•°çš„Så½¢æ›²çº¿æºäºæŒ‡æ•°å‡½æ•°çš„æ€§è´¨ï¼Œå½“ $x \\\\rightarrow -\\\\infty$ æ—¶ $e^{-x} \\\\rightarrow \\\\infty$ï¼Œä½¿å¾— $\\\\sigma(x) \\\\rightarrow 0$ï¼›å½“ $x \\\\rightarrow +\\\\infty$ æ—¶ $e^{-x} \\\\rightarrow 0$ï¼Œä½¿å¾— $\\\\sigma(x) \\\\rightarrow 1$ï¼Œè¿™ç§å•è°ƒæ€§å’Œæœ‰ç•Œæ€§æ­£æ˜¯ç¥ç»ç½‘ç»œéœ€è¦çš„éçº¿æ€§æ¿€æ´»ç‰¹æ€§","level":4,"nodeType":"answer","parentId":"' + parentId + '"}}';
  }

  const prompt = STELLARMIND_PROMPT_TEMPLATE
    .replace('{{question}}', question)
    .replace('{{parentId}}', parentId)
    .replace('{{level}}', String(level))
    .replace('{{readingLevel}}', readingLevel)
    .replace('{{levelInstructions}}', levelInstructions)
    .replace('{{expectedType}}', expectedType)
    .replace('{{examples}}', examples);

  try {
    let content = '';
    
    if (openai) {
      // ä½¿ç”¨çœŸå®çš„OpenAI API
      const response = await openai.chat.completions.create({
        model: modelId,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.5,
        max_tokens: 1500,
      });
      content = response.choices[0].message?.content || '';
    } else {
      // æ¨¡æ‹Ÿæ¨¡å¼ - ç”Ÿæˆç¤ºä¾‹èŠ‚ç‚¹
      console.log('ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ç”ŸæˆèŠ‚ç‚¹');
      content = generateMockNodes(level, expectedType, parentId);
    }
    
    if (!content) return;

    const lines = content.split('\n').filter(line => line.trim().startsWith('{'));
    const childNodes = [];

    for (const line of lines) {
      try {
        const parsed = JSON.parse(line.trim());
        if (parsed.type === 'node') {
          const newNodeId = `${parsed.data.nodeType}-${uuidv4()}`;
          const nodeWithId = {
            ...parsed,
            data: { ...parsed.data, id: newNodeId }
          };
          
          // Stream Node
          controller.enqueue(encoder.encode(`data: ${JSON.stringify(nodeWithId)}\n\n`));
          
          // Stream Edge
          const edge = { type: 'edge', data: { source: parentId, target: newNodeId } };
          controller.enqueue(encoder.encode(`data: ${JSON.stringify(edge)}\n\n`));

          childNodes.push(nodeWithId.data);
        }
      } catch (e) {
        console.warn('Failed to parse line from LLM, skipping:', line);
      }
    }
    
    // ä¿®å¤é€’å½’è°ƒç”¨é€»è¾‘ - ç¡®ä¿æ­£ç¡®é€’å½’
    for (const childNode of childNodes) {
      // å¯¹äºlevel 1çš„é—®é¢˜èŠ‚ç‚¹ï¼Œç”Ÿæˆç­”æ¡ˆèŠ‚ç‚¹
      if (level === 1 && childNode.nodeType === 'question') {
        // ä¸ºé—®é¢˜èŠ‚ç‚¹ç”Ÿæˆç­”æ¡ˆ
        await recursiveExplore(
          `è¯·å›ç­”ï¼š${childNode.content}`, 
          childNode.id, 
          level + 1, 
          controller, 
          encoder, 
          modelId,
          readingLevel
        );
      }
      // å¯¹äºlevel 2çš„ç­”æ¡ˆèŠ‚ç‚¹ï¼Œç”Ÿæˆæ·±åŒ–é—®é¢˜
      else if (level === 2 && childNode.nodeType === 'answer') {
        // ä¸ºç­”æ¡ˆèŠ‚ç‚¹ç”Ÿæˆæ·±åŒ–é—®é¢˜
        await recursiveExplore(
          `åŸºäºè¿™ä¸ªç­”æ¡ˆ"${childNode.content}"ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢ä»€ä¹ˆï¼Ÿ`, 
          childNode.id, 
          level + 1, 
          controller, 
          encoder, 
          modelId,
          readingLevel
        );
      }
      // å¯¹äºlevel 3çš„é—®é¢˜èŠ‚ç‚¹ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
      else if (level === 3 && childNode.nodeType === 'question') {
        await recursiveExplore(
          `è¯·å›ç­”ï¼š${childNode.content}`, 
          childNode.id, 
          level + 1, 
          controller, 
          encoder, 
          modelId,
          readingLevel
        );
      }
    }

  } catch (error) {
    console.error('Error during OpenAI API call:', error);
    const errorEvent = { type: 'error', data: { message: 'Failed to call AI service.' } };
    controller.enqueue(encoder.encode(`data: ${JSON.stringify(errorEvent)}\n\n`));
  }
}

export async function POST(req: NextRequest) {
  const { question, modelId, readingLevel } = await req.json();

  if (!question) {
    return new Response('Missing question in request body', { status: 400 });
  }
  
  console.log("Using model ID from request:", modelId); // Log the received model ID

  // Fallback to a default model if modelId is not provided
  const effectiveModelId = modelId || 'gpt-4o';
  console.log(`Executing exploration with model: ${effectiveModelId}`);

  // ä½¿ç”¨OpenAIç›´æ¥è°ƒç”¨ï¼Œä¸éœ€è¦LangChain
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      try {
        // 1. åˆ›å»ºå¹¶å‘é€æ ¹èŠ‚ç‚¹
        const rootId = `question-${uuidv4()}`;
        const rootNode = {
          type: 'node',
          data: {
            id: rootId,
            content: question,
            level: 0,
            nodeType: 'question',
            parentId: null,
          },
        };
        controller.enqueue(encoder.encode(`data: ${JSON.stringify(rootNode)}\n\n`));

        // 2. å¼€å§‹é€’å½’æ¢ç´¢
        await recursiveExplore(question, rootId, 1, controller, encoder, effectiveModelId, readingLevel || 'å¤§å­¦ğŸ“');
        
        // 3. å‘é€ç»“æŸä¿¡å·
        const doneEvent = { type: 'done', data: { message: 'Exploration complete.' } };
        controller.enqueue(encoder.encode(`data: ${JSON.stringify(doneEvent)}\n\n`));

        controller.close();
      } catch (error) {
        console.error('Stream error:', error);
        controller.error(error);
      }
    },
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}

export async function GET(req: NextRequest) {
  const { searchParams } = new URL(req.url);
  const question = searchParams.get('question');
  const modelId = searchParams.get('modelId');

  if (!question) {
    return NextResponse.json({ error: 'Missing question parameter' }, { status: 400 });
  }

  console.log("GET request - Using model ID:", modelId);

  // Fallback to a default model if modelId is not provided
  const effectiveModelId = modelId || 'gpt-4o';
  console.log(`GET request - Executing exploration with model: ${effectiveModelId}`);

  // For GET requests, we'll return a simple JSON response instead of streaming
  // This is useful for testing or simple integrations
  return NextResponse.json({
    message: 'Exploration endpoint is available',
    question,
    modelId: effectiveModelId,
    timestamp: new Date().toISOString(),
  });
}

export async function DELETE(req: NextRequest) {
  // This endpoint could be used to cancel ongoing explorations
  // For now, we'll just return a success response
  return NextResponse.json({
    message: 'Exploration cancelled',
    timestamp: new Date().toISOString(),
  });
} 